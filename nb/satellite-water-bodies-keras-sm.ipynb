{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c1afb4d",
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/OnurKerimoglu/water_bodies/blob/main/nb/satellite-water-bodies-keras-sm.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2e4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698cee7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "if tf.test.is_gpu_available():\n",
    "    HEIGHT, WIDTH = (512, 512)\n",
    "    BATCH_SIZE = 16\n",
    "    ENCODER = 'resnet50'\n",
    "    DEVICE = 'cuda'\n",
    "    FLAG_CUDA = True\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"segmentation-models\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"opencv-python\"])\n",
    "    # subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"albumentations\"])\n",
    "    percentdata2use=100\n",
    "else:\n",
    "    HEIGHT, WIDTH = (256, 256)\n",
    "    BATCH_SIZE = 128\n",
    "    ENCODER = 'resnet18'\n",
    "    DEVICE = 'cpu'\n",
    "    FLAG_CUDA = False\n",
    "    percentdata2use=25\n",
    "WEIGHTS = 'imagenet'\n",
    "ROOTPATH = os.path.dirname(os.path.abspath(os.path.curdir))\n",
    "print(f'rootpath: {ROOTPATH}, cuda available: {FLAG_CUDA}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b973bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\" \n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a12e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
    "# THEN FEEL FREE TO DELETE THIS CELL.\n",
    "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
    "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
    "# NOTEBOOK.\n",
    "import kagglehub\n",
    "franciscoescobar_satellite_images_of_water_bodies_path = kagglehub.dataset_download('franciscoescobar/satellite-images-of-water-bodies')\n",
    "\n",
    "print('Data source import complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c86f5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "franciscoescobar_satellite_images_of_water_bodies_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d24192",
   "metadata": {},
   "outputs": [],
   "source": [
    "Images_dir = os.path.join(franciscoescobar_satellite_images_of_water_bodies_path, 'Water Bodies Dataset', 'Images')\n",
    "Masks_dir = os.path.join(franciscoescobar_satellite_images_of_water_bodies_path, 'Water Bodies Dataset', 'Masks')\n",
    "image_paths = sorted(glob.glob(f'{Images_dir}/*'))\n",
    "mask_paths = sorted(glob.glob(f'{Masks_dir}/*'))\n",
    "\n",
    "num_images_to_use = round(len(image_paths) * percentdata2use / 100)\n",
    "image_paths = image_paths[:num_images_to_use]\n",
    "mask_paths = mask_paths[:num_images_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09162603",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(mask_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a2fd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Capture training image info as a list\n",
    "img_np_pr = []\n",
    "\n",
    "for img_path in image_paths:\n",
    "    #print(img_path)\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
    "    img = cv2.resize(img, (WIDTH, HEIGHT))\n",
    "    # img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img = img/255.0\n",
    "    img_np_pr.append(img)\n",
    "    #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing        \n",
    "img_np_pr = np.array(img_np_pr)\n",
    "\n",
    "#Capture mask/label info as a list\n",
    "mask_np_pr = [] \n",
    "for mask_path in mask_paths:\n",
    "    mask = cv2.imread(mask_path, 0)       \n",
    "    mask = cv2.resize(mask, (WIDTH, HEIGHT))\n",
    "    #mask = cv2.cvtColor(mask, cv2.COLOR_RGB2BGR)\n",
    "    mask = mask/255.0\n",
    "    mask_np_pr.append(mask)\n",
    "    #train_labels.append(label)\n",
    "#Convert list to array for machine learning processing          \n",
    "mask_np_pr = np.array(mask_np_pr)\n",
    "mask_np_pr = np.expand_dims(mask_np_pr, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad27592",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_np_pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e0a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "num=2\n",
    "axarr[0].imshow(img_np_pr[num])\n",
    "axarr[1].imshow(mask_np_pr[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_np_pr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110d210",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_np_pr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use customary x_train and y_train variables\n",
    "X = img_np_pr\n",
    "Y = mask_np_pr\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc540ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess input\n",
    "preprocess_input = sm.get_preprocessing(ENCODER)\n",
    "x_train = preprocess_input(x_train)\n",
    "x_val = preprocess_input(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16866733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = sm.Unet(ENCODER, encoder_weights=WEIGHTS)\n",
    "# bce_jaccard_loss = sm.losses.bce_jaccard_loss\n",
    "dice_loss = sm.losses.DiceLoss()\n",
    "bce_loss = sm.losses.BinaryCELoss()\n",
    "# focal_loss = sm.losses.BinaryFocalLoss()\n",
    "# total_loss = sm.losses.bce_dice_loss + (1 * focal_loss)\n",
    "total_loss = bce_loss + dice_loss\n",
    "\n",
    "model.compile(\n",
    "    'Adam',\n",
    "    # loss=bce_jaccard_loss,\n",
    "    loss = total_loss,\n",
    "    metrics=[sm.metrics.iou_score],)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13dab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_f = tf.cast(y_train, dtype=tf.float32)\n",
    "# y_val_f = tf.cast(y_val, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b58b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb0b8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6c2bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1986950a",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,2)\n",
    "num=3\n",
    "axarr[0].imshow(x_val[num])\n",
    "axarr[1].imshow(y_val[num])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1711f2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_training_logs = os.path.join(ROOTPATH, 'training_logs')\n",
    "if not os.path.exists(path_training_logs):\n",
    "    os.makedirs(path_training_logs)\n",
    "\n",
    "path_models = os.path.join(ROOTPATH, 'models', 'keras_tensorflow_unet', ENCODER)\n",
    "if not os.path.exists(path_models):\n",
    "    os.makedirs(path_models)\n",
    "    \n",
    "import keras\n",
    "EScallback = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    patience=3)\n",
    "\n",
    "TBcallback = keras.callbacks.TensorBoard(\n",
    "    log_dir=path_models,\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=False\n",
    ")\n",
    "\n",
    "CPcallback = keras.callbacks.ModelCheckpoint(\n",
    "    os.path.join(path_models, 'best_model.weights.h5'), \n",
    "    save_weights_only=True, \n",
    "    save_best_only=True,\n",
    "    mode='min')\n",
    "\n",
    "RLRcallback =keras.callbacks.ReduceLROnPlateau()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faacf4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "   x=x_train,\n",
    "   y=y_train,\n",
    "   batch_size=BATCH_SIZE,\n",
    "   epochs=5,\n",
    "   validation_data=(x_val, y_val),\n",
    "   callbacks=[TBcallback, EScallback, CPcallback,RLRcallback],\n",
    "   verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dcc539",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(x_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69644533",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e614921",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb8598d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['iou_score'])\n",
    "plt.plot(history.history['val_iou_score'])\n",
    "plt.title('model iou score')\n",
    "plt.ylabel('iou_score')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aaf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = '../models/water_bodies_EncResnet34_10epochs.keras'\n",
    "model.save(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b644a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(fpath, compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0787f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test on a different image\n",
    "#READ EXTERNAL IMAGE...\n",
    "num = 0\n",
    "image = cv2.imread(\n",
    "    image_paths[num], \n",
    "    cv2.IMREAD_COLOR)     \n",
    "image = cv2.resize(image, (SIZE_Y, SIZE_X))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "image = preprocess_input(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11840165",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = cv2.imread(\n",
    "    mask_paths[num], \n",
    "    0)     \n",
    "mask = cv2.resize(mask, (SIZE_Y, SIZE_X))\n",
    "# mask = np.expand_dims(mask, axis=0)\n",
    "\n",
    "pred_mask = model.predict(\n",
    "    np.expand_dims(image, axis=0)\n",
    "    )\n",
    "logits_mask = pred_mask.squeeze()\n",
    "# logits_mask = cv2.cvtColor(pred_mask, cv2.COLOR_RGB2BGR)\n",
    "pred_mask=tf.sigmoid(logits_mask)\n",
    "pred_mask=(pred_mask > 0.5)*1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c2d985",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask = model.predict(\n",
    "    np.expand_dims(image, axis=0)\n",
    "    )\n",
    "pred_mask = pred_mask.squeeze()\n",
    "pred_mask = tf.sigmoid(pred_mask)\n",
    "pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce18d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c7584b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axarr = plt.subplots(1,3)\n",
    "axidx = 0\n",
    "axarr[axidx].imshow(image)\n",
    "axarr[axidx].set_title('Image')\n",
    "axidx += 1\n",
    "axarr[axidx].imshow(np.squeeze(mask), cmap='gray')\n",
    "axarr[axidx].set_title('Mask')\n",
    "axidx += 1\n",
    "axarr[axidx].imshow(pred_mask)\n",
    "axarr[axidx].set_title('Predicted Mask')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
